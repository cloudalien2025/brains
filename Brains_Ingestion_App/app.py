from __future__ import annotations

import platform
from pathlib import Path
from uuid import uuid4

import streamlit as st

from adapters.extraction import extract_brain_core_records
from adapters.transcription import transcribe
from adapters.youtube_discovery import discover_videos
from brainpack.exporters import write_json, write_jsonl, write_sources_csv
from brainpack.utils import now_iso, slugify
from brainpack.validators import (
    validate_pack_manifest,
    validate_record,
    validate_run_metadata,
    validate_source,
)


st.set_page_config(page_title="Brains Ingestion MVP", layout="wide")
st.title("Brains Ingestion MVP")

keyword = st.text_input("Keyword", value="boutique hotels")
max_videos = st.number_input("Max videos", min_value=1, max_value=100, value=25, step=1)
discovery_only = st.toggle("Discovery only", value=False)

if "log" not in st.session_state:
    st.session_state.log = []


def log(message: str) -> None:
    st.session_state.log.append(message)


if st.button("Generate Brain Pack", type="primary"):
    st.session_state.log = []
    errors: list[str] = []
    started_at = now_iso()

    videos = discover_videos(keyword=keyword, max_videos=int(max_videos))
    log(f"Discovered {len(videos)} videos for '{keyword}'.")

    for src in videos:
        errors.extend([f"source:{src.get('source_id', 'unknown')} {err}" for err in validate_source(src)])

    queue = videos[: int(max_videos)]
    transcripts = []
    records = []

    if not discovery_only and not errors:
        transcripts = [transcribe(item) for item in queue]
        log(f"Transcribed {len(transcripts)} queued videos.")
        records = extract_brain_core_records(keyword, transcripts)
        log(f"Extracted {len(records)} brain_core records.")
        for rec in records:
            errors.extend([f"record:{rec.get('id', 'unknown')} {err}" for err in validate_record(rec)])

    run_metadata = {
        "run_id": f"run_{uuid4().hex[:8]}",
        "keyword": keyword,
        "started_at": started_at,
        "ended_at": now_iso(),
        "config": {"max_videos": int(max_videos), "discovery_only": discovery_only},
        "errors": errors,
        "env": {
            "python_version": platform.python_version(),
            "platform": platform.platform(),
            "has_youtube_api_key": False,
        },
    }

    errors.extend([f"run_metadata {err}" for err in validate_run_metadata(run_metadata)])

    pack_slug = slugify(keyword)
    pack_name = f"{started_at[:10]}__{pack_slug}__pack_v1"
    pack_dir = Path(__file__).resolve().parents[1] / "BD_Brain" / "Packs" / pack_name

    outputs = {
        "Brain_Additions.md": "Brain_Additions.md",
        "Brain_Core.jsonl": "Brain_Core.jsonl",
        "Brain_Diff.md": "Brain_Diff.md",
        "Sources.csv": "Sources.csv",
        "Run_Metadata.json": "Run_Metadata.json",
    }

    manifest = {
        "pack_id": pack_name,
        "brain": "BD_Brain",
        "keyword": keyword,
        "created_at": now_iso(),
        "sources": queue,
        "outputs": outputs,
        "stats": {
            "videos_discovered": len(videos),
            "videos_queued": len(queue),
            "records_extracted": len(records),
        },
    }

    errors.extend([f"pack_manifest {err}" for err in validate_pack_manifest(manifest)])

    if errors:
        st.error("Validation failed. No output written.")
        for err in errors:
            st.write(f"- {err}")
    else:
        pack_dir.mkdir(parents=True, exist_ok=True)
        (pack_dir / "Brain_Additions.md").write_text(
            "# Brain Additions\n\nGenerated by ingestion MVP.\n", encoding="utf-8"
        )
        (pack_dir / "Brain_Diff.md").write_text("# Brain Diff\n\nInitial MVP diff.\n", encoding="utf-8")
        write_jsonl(pack_dir / "Brain_Core.jsonl", records)
        write_sources_csv(pack_dir / "Sources.csv", queue)
        write_json(pack_dir / "Run_Metadata.json", run_metadata)
        write_json(pack_dir / "Pack_Manifest.json", manifest)
        log(f"Pack written: {pack_dir}")
        st.success(f"Generated Brain Pack at: {pack_dir}")

    with st.expander("Discovery results", expanded=True):
        st.json(videos)

    with st.expander("Queue", expanded=False):
        st.json(queue)

    with st.expander("Run log", expanded=True):
        st.write("\n".join(st.session_state.log) if st.session_state.log else "No log entries.")

    with st.expander("Outputs", expanded=True):
        st.json(outputs)
